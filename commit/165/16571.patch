From 1c411a7913516c3de8c56413d5c0b021d128e421 Mon Sep 17 00:00:00 2001
From: GitHub Action <action@github.com>
Date: Wed, 7 Jan 2026 05:51:39 +0000
Subject: [PATCH] feat: Squash PR #16571 changes

---
 python/sglang/srt/layers/layernorm.py | 28 +++++++++++-
 python/sglang/srt/models/qwen3_vl.py  | 65 ++++++++++++++++++++-------
 2 files changed, 76 insertions(+), 17 deletions(-)

diff --git a/python/sglang/srt/layers/layernorm.py b/python/sglang/srt/layers/layernorm.py
index 7bef9d2ab..b491e4e69 100644
--- a/python/sglang/srt/layers/layernorm.py
+++ b/python/sglang/srt/layers/layernorm.py
@@ -65,6 +65,7 @@ if _is_cuda or _is_xpu:
         rmsnorm,
     )
 if _use_aiter:
+    from aiter import layer_norm, layernorm2d_fwd_with_add
     from aiter import rmsnorm2d_fwd as rms_norm
     from aiter import rmsnorm2d_fwd_with_add as fused_add_rms_norm
 elif _is_hip:
@@ -308,18 +309,21 @@ class LayerNorm(MultiPlatformOp):
         eps: float = 1e-6,
         elementwise_affine: bool = True,
         bias: bool = True,
-        dtype: torch.dtype = torch.float32,
+        weight_dtype: Optional[torch.dtype] = None,
     ) -> None:
         super().__init__()
         self.hidden_size = hidden_size
         self.variance_epsilon = eps
         self.elementwise_affine = elementwise_affine
         self.use_bias = bias
-        self.dtype = dtype
+        self.dtype = weight_dtype
 
         self.bias = nn.Parameter(torch.zeros(hidden_size, dtype=self.dtype))
         self.weight = nn.Parameter(torch.ones(hidden_size, dtype=self.dtype))
 
+        if _use_aiter:
+            self._forward_method = self.forward_aiter
+
     def forward_cuda(
         self,
         x: torch.Tensor,
@@ -377,6 +381,26 @@ class LayerNorm(MultiPlatformOp):
         else:
             return self.forward_native(x, **kwargs)
 
+    def forward_aiter(
+        self,
+        x: torch.Tensor,
+        residual: Optional[torch.Tensor] = None,
+    ) -> Union[torch.Tensor, Tuple[torch.Tensor, torch.Tensor]]:
+        if residual is not None:
+            residual_out = torch.empty_like(x)
+            output = torch.empty_like(x)
+            layernorm2d_fwd_with_add(
+                output,
+                x,
+                residual,
+                residual_out,
+                self.weight.data,
+                self.bias.data,
+                self.variance_epsilon,
+            )
+            return output, residual_out
+        return layer_norm(x, self.weight.data, self.bias.data, self.variance_epsilon)
+
 
 class GemmaRMSNorm(MultiPlatformOp):
     def __init__(
diff --git a/python/sglang/srt/models/qwen3_vl.py b/python/sglang/srt/models/qwen3_vl.py
index 6c06aaa0e..eb54ccaab 100644
--- a/python/sglang/srt/models/qwen3_vl.py
+++ b/python/sglang/srt/models/qwen3_vl.py
@@ -33,6 +33,7 @@ from sglang.srt.distributed.parallel_state import get_pp_group
 from sglang.srt.environ import envs
 from sglang.srt.layers.attention.vision import VisionAttention
 from sglang.srt.layers.dp_attention import is_dp_attention_enabled
+from sglang.srt.layers.layernorm import LayerNorm
 from sglang.srt.layers.linear import ColumnParallelLinear, RowParallelLinear
 from sglang.srt.layers.logits_processor import LogitsProcessor
 from sglang.srt.layers.pooler import Pooler, PoolingType
@@ -63,11 +64,12 @@ from sglang.srt.models.utils import (
 from sglang.srt.multimodal.mm_utils import run_dp_sharded_mrope_vision_model
 from sglang.srt.multimodal.vit_cuda_graph_runner import ViTCudaGraphRunner
 from sglang.srt.server_args import get_global_server_args
-from sglang.srt.utils import add_prefix, get_int_env_var, is_npu
+from sglang.srt.utils import add_prefix, get_int_env_var, is_hip, is_npu
 from sglang.srt.utils.hf_transformers_utils import get_processor
 
 logger = logging.getLogger(__name__)
-
+_is_hip = is_hip()
+_use_aiter = get_int_env_var("SGLANG_USE_AITER") and _is_hip
 
 # === Vision Encoder === #
 
@@ -162,7 +164,10 @@ class Qwen3_VisionBlock(nn.Module):
     ) -> None:
         super().__init__()
         if norm_layer is None:
-            norm_layer = partial(nn.LayerNorm, eps=1e-6)
+            if _use_aiter:
+                norm_layer = partial(LayerNorm, eps=1e-6)
+            else:
+                norm_layer = partial(nn.LayerNorm, eps=1e-6)
         self.norm1 = norm_layer(dim)
         self.norm2 = norm_layer(dim)
 
@@ -194,8 +199,15 @@ class Qwen3_VisionBlock(nn.Module):
         rotary_pos_emb_cos: torch.Tensor,
         rotary_pos_emb_sin: torch.Tensor,
         output_ws: Optional[torch.Tensor] = None,
+        residual: Optional[torch.Tensor] = None,
     ) -> torch.Tensor:
-        hidden_states = self.norm1(x)
+        # First norm
+        if residual is None:
+            hidden_states = self.norm1(x)
+            residual = x
+        else:
+            hidden_states, residual = self.norm1(x, residual=residual)
+
         hidden_states = rearrange(hidden_states, "s b ... -> b s ...")
         attn = self.attn(
             hidden_states,
@@ -205,11 +217,16 @@ class Qwen3_VisionBlock(nn.Module):
             output_ws=output_ws,
         )
         attn = rearrange(attn, "b s ... -> s b ...")
-        x += attn
-        norm2 = self.norm2(x)
+        # Fused add + norm2
+        if isinstance(self.norm2, LayerNorm):
+            norm2, x = self.norm2(attn, residual=residual)
+        else:
+            x = x + attn
+            norm2 = self.norm2(x)
+
+        # MLP and final residual
         mlp = self.mlp(norm2)
-        x += mlp
-        return x
+        return mlp, x
 
 
 class Qwen3VLMoeVisionPatchMerger(nn.Module):
@@ -259,11 +276,23 @@ class Qwen3VLMoeVisionPatchMerger(nn.Module):
             tp_rank=self.tp_rank,
         )
 
-    def forward(self, x: torch.Tensor) -> torch.Tensor:
+    def forward(
+        self, x: torch.Tensor, residual: Optional[torch.Tensor] = None
+    ) -> torch.Tensor:
         if self.use_postshuffle_norm:
-            x = self.norm(x.view(-1, self.hidden_size))
+            if residual is not None:
+                x, _ = self.norm(
+                    x.view(-1, self.hidden_size),
+                    residual=residual.view(-1, self.hidden_size),
+                )
+            else:
+                x = self.norm(x.view(-1, self.hidden_size))
         else:
-            x = self.norm(x).view(-1, self.hidden_size)
+            if residual is not None:
+                x, _ = self.norm(x, residual=residual)
+                x = x.view(-1, self.hidden_size)
+            else:
+                x = self.norm(x).view(-1, self.hidden_size)
 
         x_parallel, _ = self.linear_fc1(x)
         x_parallel = self.act_fn(x_parallel)
@@ -313,7 +342,10 @@ class Qwen3VLMoeVisionModel(nn.Module, RotaryPosMixin):
         else:
             self.pos_embed = PPMissingLayer()
 
-        norm_layer = partial(nn.LayerNorm, eps=norm_eps)
+        if _use_aiter:
+            norm_layer = partial(LayerNorm, eps=norm_eps)
+        else:
+            norm_layer = partial(nn.LayerNorm, eps=norm_eps)
         head_dim = self.hidden_size // self.num_heads
         self.rotary_pos_emb = get_rope(
             head_size=head_dim,
@@ -455,22 +487,25 @@ class Qwen3VLMoeVisionModel(nn.Module, RotaryPosMixin):
 
         deepstack_feature_lists = []
         num_deepstack_captured = 0
+        residual = None
 
         for layer_num, blk in enumerate(self.blocks):
-            x = blk(
+            x, residual = blk(
                 x,
                 cu_seqlens=cu_seqlens,
                 rotary_pos_emb_cos=rotary_pos_emb_cos,
                 rotary_pos_emb_sin=rotary_pos_emb_sin,
+                residual=residual,
             )
 
             if layer_num in self.deepstack_visual_indexes:
                 deepstack_feature = self.deepstack_merger_list[num_deepstack_captured](
-                    x
+                    x,
+                    residual=residual,
                 )
                 deepstack_feature_lists.append(deepstack_feature)
                 num_deepstack_captured += 1
-        x = self.merger(x)
+        x = self.merger(x, residual=residual)
         hidden_states = torch.cat(
             [x] + deepstack_feature_lists, dim=1
         )  # [seq_len, hidden_size * (1 + depth_of_deepstack)]
-- 
2.52.0

